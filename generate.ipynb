{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from models import MelodyLSTM\n",
    "from pathlib import Path\n",
    "from prepare_data import encoding\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def sample_with_temperature(scores, t: float = 1.0):\n",
    "    prob = scores ** (1.0 / t)\n",
    "    # I assume np normalizes p to sum to 1.\n",
    "    prob = prob / sum(prob)  # TODO Maybe make more numerically stable, logsumexp.\n",
    "    return np.random.choice(range(len(scores)), p=prob).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s6/6dqtmwnd33v0v_jdhdk1kk8r0000gn/T/ipykernel_70499/351142733.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_dict = torch.load(model_file)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MelodyLSTM(\n",
       "  (embedding): Embedding(132, 8)\n",
       "  (lstm): LSTM(8, 8)\n",
       "  (fc): Linear(in_features=8, out_features=132, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_file = Path(\"models/model_time_series_2024-10-15T20-31-27.pth\")\n",
    "model_dict = torch.load(model_file)\n",
    "config, state_dict = model_dict[\"config\"], model_dict[\"state_dict\"]\n",
    "\n",
    "model = MelodyLSTM(\n",
    "    num_unique_tokens=config[\"num_unique_tokens\"],\n",
    "    embedding_size=config[\"embedding_size\"],\n",
    "    hidden_size=config[\"hidden_size\"],\n",
    ")\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Illustration: generating without randomness\n",
    "\n",
    "Given a starting note sequence, below is the continuation from the model when taking the most \"likely\" next note. It just predicts a `HOLD` token (`129`) because the grid was 16th notes so there are many hold tokens. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[36,\n",
       " 129,\n",
       " 129,\n",
       " 129,\n",
       " 37,\n",
       " 38,\n",
       " 129,\n",
       " 129,\n",
       " 129,\n",
       " 129,\n",
       " 129,\n",
       " 129,\n",
       " 129,\n",
       " 129,\n",
       " 129,\n",
       " 129,\n",
       " 129,\n",
       " 129]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_melody(model, initial_sequence, num_notes, sequence_length):\n",
    "    melody = list(initial_sequence)\n",
    "    for i in range(num_notes):\n",
    "        inputs = melody[-sequence_length:]\n",
    "        scores = model(inputs)[-1]\n",
    "        next_item = torch.argmax(scores).item()\n",
    "        melody.append(next_item)\n",
    "    return melody\n",
    "\n",
    "\n",
    "seq1 = [\"36\", \"H\", \"H\", \"H\", \"37\", \"38\", \"H\", \"H\"]\n",
    "scores = torch.exp(model([encoding[e] for e in seq1])[-1]).detach()\n",
    "generate_melody(\n",
    "    model=model,\n",
    "    initial_sequence=[encoding[e] for e in seq1],\n",
    "    num_notes=10,\n",
    "    sequence_length=config[\"sequence_length\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the model scores (predictions) for the next note in the sequence. Instead of selecting the note with the largest score, we will instead sample from this distribution, or a slightly modified version of it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3, 3))\n",
    "\n",
    "plt.barh(range(len(scores)), scores)\n",
    "plt.xlabel(\"Model scores\")\n",
    "plt.ylabel(\"MIDI Notes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[30,\n",
       " 129,\n",
       " 129,\n",
       " 129,\n",
       " 30,\n",
       " 32,\n",
       " 129,\n",
       " 129,\n",
       " 60,\n",
       " 71,\n",
       " 129,\n",
       " 129,\n",
       " 129,\n",
       " 129,\n",
       " 129,\n",
       " 62,\n",
       " 129,\n",
       " 128,\n",
       " 129,\n",
       " 129]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_melody2(\n",
    "    model, initial_sequence, num_notes, sequence_length, temperature=1.0\n",
    "):\n",
    "    melody = list(initial_sequence)\n",
    "    for i in range(num_notes):\n",
    "        inputs = melody[-sequence_length:]\n",
    "        scores = np.exp(model(inputs)[-1].detach().numpy())\n",
    "        next_item = sample_with_temperature(scores, t=temperature)\n",
    "        melody.append(next_item)\n",
    "    return melody\n",
    "\n",
    "\n",
    "np.random.seed(202)\n",
    "seq1 = [\"30\", \"H\", \"H\", \"H\", \"30\", \"32\", \"H\", \"H\"]\n",
    "mel1 = generate_melody2(\n",
    "    model=model,\n",
    "    initial_sequence=[encoding[e] for e in seq1],\n",
    "    num_notes=100,\n",
    "    sequence_length=config[\"sequence_length\"],\n",
    "    temperature=1.0,\n",
    ")\n",
    "mel1[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save to midi\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoding = {v: k for k, v in encoding.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import music21 as m21\n",
    "from prepare_data import HOLD, REST\n",
    "\n",
    "\n",
    "def time_series_to_midi(\n",
    "    sequence: list[str],\n",
    "    step_duration: float,\n",
    "    filename: str | Path = None,\n",
    "    hold_token=HOLD,\n",
    "    rest_token=REST,\n",
    "):\n",
    "    \"\"\"Convert a time series melody to midi\n",
    "\n",
    "    Args:\n",
    "        sequence: list of strings. A melody as notes or rests or hold tokens at fixed time steps.\n",
    "        filename: Path to save midi file. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        music21 stream\n",
    "    \"\"\"\n",
    "    stream = m21.stream.Stream()\n",
    "\n",
    "    step = 1\n",
    "    for e in sequence:\n",
    "        if e == hold_token:\n",
    "            step += 1\n",
    "        else:\n",
    "            length = step_duration * step\n",
    "            if e == rest_token:\n",
    "                note = m21.note.Rest(quarterLength=length)\n",
    "            else:\n",
    "                note = m21.note.Note(pitch=int(e), quarterLength=length)\n",
    "            stream.append(note)\n",
    "            step = 1\n",
    "\n",
    "    if filename is not None:\n",
    "        stream.write(fmt=\"midi\", fp=filename)\n",
    "    return stream\n",
    "\n",
    "\n",
    "stream1 = time_series_to_midi([decoding[e] for e in mel1], step_duration=1)\n",
    "stream1.show(\"midi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline generators\n",
    "\n",
    "#TODO Make baseline generators: \n",
    "\n",
    "- uniform over tokens\n",
    "- uniform over neighboring notes\n",
    "- prob proportional to distance \n",
    "\n",
    "distance = pitch and chroma, also condition on a key?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
