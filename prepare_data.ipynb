{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2024-10-04\n",
    "\n",
    "convert midi files to a representation for a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1276\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PosixPath('2013/ORIG-MIDI_01_7_7_13_Group__MID--AUDIO_12_R1_2013_wav--1.midi'),\n",
       " PosixPath('2013/ORIG-MIDI_03_7_6_13_Group__MID--AUDIO_09_R1_2013_wav--2.midi'),\n",
       " PosixPath('2013/ORIG-MIDI_01_7_7_13_Group__MID--AUDIO_13_R1_2013_wav--1.midi'),\n",
       " PosixPath('2013/ORIG-MIDI_03_7_6_13_Group__MID--AUDIO_10_R1_2013_wav--2.midi'),\n",
       " PosixPath('2013/ORIG-MIDI_01_7_6_13_Group__MID--AUDIO_01_R1_2013_wav--2.midi'),\n",
       " PosixPath('2013/ORIG-MIDI_01_7_10_13_Group_MID--AUDIO_08_R3_2013_wav--2.midi'),\n",
       " PosixPath('2013/ORIG-MIDI_01_7_6_13_Group__MID--AUDIO_02_R1_2013_wav--2.midi'),\n",
       " PosixPath('2013/ORIG-MIDI_02_7_6_13_Group__MID--AUDIO_08_R1_2013_wav--3.midi'),\n",
       " PosixPath('2013/ORIG-MIDI_01_7_6_13_Group__MID--AUDIO_04_R1_2013_wav--3.midi'),\n",
       " PosixPath('2013/ORIG-MIDI_01_7_6_13_Group__MID--AUDIO_03_R1_2013_wav--2.midi'),\n",
       " PosixPath('2013/ORIG-MIDI_01_7_7_13_Group__MID--AUDIO_11_R1_2013_wav--1.midi'),\n",
       " PosixPath('2013/ORIG-MIDI_03_7_10_13_Group_MID--AUDIO_18_R3_2013_wav--2.midi'),\n",
       " PosixPath('2013/ORIG-MIDI_02_7_6_13_Group__MID--AUDIO_06_R1_2013_wav--4.midi'),\n",
       " PosixPath('2013/ORIG-MIDI_02_7_8_13_Group__MID--AUDIO_14_R2_2013_wav--4.midi'),\n",
       " PosixPath('2013/ORIG-MIDI_03_7_8_13_Group__MID--AUDIO_19_R2_2013_wav--3.midi'),\n",
       " PosixPath('2013/ORIG-MIDI_03_7_10_13_Group_MID--AUDIO_18_R3_2013_wav--3.midi'),\n",
       " PosixPath('2013/ORIG-MIDI_01_7_6_13_Group__MID--AUDIO_03_R1_2013_wav--3.midi'),\n",
       " PosixPath('2013/ORIG-MIDI_02_7_10_13_Group_MID--AUDIO_12_R3_2013_wav--4.midi'),\n",
       " PosixPath('2013/ORIG-MIDI_01_7_6_13_Group__MID--AUDIO_04_R1_2013_wav--2.midi'),\n",
       " PosixPath('2013/ORIG-MIDI_03_7_8_13_Group__MID--AUDIO_18_R2_2013_wav--3.midi'),\n",
       " PosixPath('2013/ORIG-MIDI_02_7_6_13_Group__MID--AUDIO_08_R1_2013_wav--2.midi'),\n",
       " PosixPath('2013/ORIG-MIDI_01_7_10_13_Group_MID--AUDIO_08_R3_2013_wav--3.midi'),\n",
       " PosixPath('2013/ORIG-MIDI_01_7_6_13_Group__MID--AUDIO_01_R1_2013_wav--3.midi'),\n",
       " PosixPath('2013/ORIG-MIDI_03_7_6_13_Group__MID--AUDIO_10_R1_2013_wav--3.midi'),\n",
       " PosixPath('2013/ORIG-MIDI_02_7_7_13_Group__MID--AUDIO_19_R1_2013_wav--1.midi'),\n",
       " PosixPath('2013/ORIG-MIDI_03_7_6_13_Group__MID--AUDIO_09_R1_2013_wav--3.midi'),\n",
       " PosixPath('2013/ORIG-MIDI_02_7_7_13_Group__MID--AUDIO_18_R1_2013_wav--1.midi'),\n",
       " PosixPath('2013/ORIG-MIDI_01_7_7_13_Group__MID--AUDIO_14_R1_2013_wav--1.midi'),\n",
       " PosixPath('2013/ORIG-MIDI_01_7_8_13_Group__MID--AUDIO_02_R2_2013_wav--5.midi'),\n",
       " PosixPath('2013/ORIG-MIDI_03_7_8_13_Group__MID--AUDIO_17_R2_2013_wav--3.midi')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import music21 as m21\n",
    "\n",
    "path_to_data = Path(\"/Users/savv/datasets/maestro-v3.0.0\")\n",
    "\n",
    "midi_files = [p.relative_to(path_to_data) for p in path_to_data.glob(\"**/*.midi\")]\n",
    "\n",
    "print(len(midi_files))\n",
    "\n",
    "midi_files[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<music21.stream.Score 0x121146c50>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = (\n",
    "    path_to_data / \"2013/ORIG-MIDI_01_7_7_13_Group__MID--AUDIO_12_R1_2013_wav--1.midi\"\n",
    ")\n",
    "midi = m21.converter.parse(file)\n",
    "midi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<music21.stream.Score 0x10b122f20>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parts = m21.instrument.partitionByInstrument(midi)\n",
    "parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<music21.stream.Part Piano>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "part = list(midi.parts)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s6/6dqtmwnd33v0v_jdhdk1kk8r0000gn/T/ipykernel_61368/3210198517.py:1: StreamIteratorInefficientWarning: recurse is not defined on StreamIterators. Call .stream() first for efficiency\n",
      "  note = list(parts.parts.recurse())[8]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(49, 0.75)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pitch = list(parts.parts.recurse())[8]\n",
    "\n",
    "pitch.pitch.midi, pitch.duration.quarterLength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s6/6dqtmwnd33v0v_jdhdk1kk8r0000gn/T/ipykernel_61368/27097895.py:1: StreamIteratorInefficientWarning: recurse is not defined on StreamIterators. Call .stream() first for efficiency\n",
      "  rest = list(parts.parts.recurse())[10]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Fraction(1, 12)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rest = list(parts.parts.recurse())[10]\n",
    "\n",
    "rest.duration.quarterLength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s6/6dqtmwnd33v0v_jdhdk1kk8r0000gn/T/ipykernel_60449/1421589813.py:1: StreamIteratorInefficientWarning: recurse is not defined on StreamIterators. Call .stream() first for efficiency\n",
      "  chord = list(parts.parts.recurse())[11]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([61, 77], 0.25)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chord = list(parts.parts.recurse())[11]\n",
    "\n",
    "([n.pitch.midi for n in chord.notes], chord.duration.quarterLength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<music21.note.Rest 1/12ql>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two options for encoding duration: \n",
    "\n",
    "- Express duration as 16ths (integer multiples of 0.25). A \"hold\" token allows longer durations.\n",
    "    - triplets are lost (rounded down to 16ths)\n",
    "- combine note+duration tokens e.g. C4-16th, C4-8th\n",
    "\n",
    "what to do with octaves? \n",
    "\n",
    "- can use a 2-octave range for a melody, and clip everything inside it. may not be straightforward (when wrapping around it will be weird). \n",
    "    - could encode using intervals (+3, -2). easier to specify single note jumps than a range for the whole melody\n",
    "\n",
    "what to do with chords?\n",
    "\n",
    "- if one-hot encoded then just allow multiple notes to be on at the same time\n",
    "- with interval-encoding it's more difficult maybe. no it's the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('R', 2.0),\n",
       " ('R', 2.0),\n",
       " (77, Fraction(1, 3)),\n",
       " (49, 0.75),\n",
       " (68, Fraction(1, 3)),\n",
       " ('R', Fraction(1, 12)),\n",
       " (61, 0.25),\n",
       " ('R', 0.5),\n",
       " (73, 0.25),\n",
       " (51, 0.75),\n",
       " (78, 0.25),\n",
       " ('R', 0.25),\n",
       " (78, 0.25),\n",
       " (61, Fraction(1, 3)),\n",
       " ('R', 0.5),\n",
       " ('R', Fraction(4, 3)),\n",
       " (73, 0.25),\n",
       " (53, 1.0),\n",
       " ('R', Fraction(1, 6)),\n",
       " (73, 0.25)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "REST = \"R\"\n",
    "\n",
    "\n",
    "def get_note_list(file: Path | str, rest=REST) -> list[int | tuple | str, float]:\n",
    "    \"\"\"Get note list from midi file\n",
    "\n",
    "    Args:\n",
    "        file: path to midi file\n",
    "\n",
    "    Returns:\n",
    "        list of (note, duration) tuples where:\n",
    "\n",
    "        - note: midi note number, tuple of midi note numbers, or rest.\n",
    "        - duration: fraction of quarter note\n",
    "    \"\"\"\n",
    "    song = m21.converter.parse(file)\n",
    "    instruments = m21.instrument.partitionByInstrument(song).parts\n",
    "    instrument = instruments[0]  # Use first instrument.\n",
    "    notes = []\n",
    "    for event in instrument.recurse():\n",
    "        if isinstance(event, m21.note.Note):\n",
    "            note = event.pitch.midi\n",
    "        elif isinstance(event, m21.note.Rest):\n",
    "            note = rest\n",
    "        elif isinstance(event, m21.chord.Chord):\n",
    "            # note = tuple(n.pitch.midi for n in event.notes)\n",
    "            note = event.notes[0].pitch.midi  # Save first note in chord.\n",
    "        else:\n",
    "            continue\n",
    "        notes.append((note, event.duration.quarterLength))\n",
    "    return notes\n",
    "\n",
    "\n",
    "get_note_list(file)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'S R H H H H H H H R H H H H H H H 77 49 H H 68 R 6'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode to (122, _, _, 22, _, -1, _) and round durations.\n",
    "\n",
    "HOLD = \"H\"\n",
    "START = \"S\"\n",
    "END = \"E\"\n",
    "note_list = get_note_list(file)\n",
    "\n",
    "\n",
    "def encode_event_list(event_list: list[int | str], step=0.25) -> str:\n",
    "    \"\"\"Encode a list of (note, duration) events to a time series representation\n",
    "\n",
    "    Args:\n",
    "        event_list: list of (note, duration) events\n",
    "        step: Step size for time series (sampling step). Fraction of quarter note. Defaults to 0.25.\n",
    "\n",
    "    Returns:\n",
    "        string\n",
    "    \"\"\"\n",
    "    encoded_note_list = [START]\n",
    "    for note, duration in event_list:\n",
    "        num_steps = max(1, int(duration / step))\n",
    "        encoded_note_list.append(note)\n",
    "        encoded_note_list.extend([HOLD] * (num_steps - 1))\n",
    "    encoded_note_list.append(END)\n",
    "\n",
    "    return encoded_note_list\n",
    "\n",
    "\n",
    "encoded_note_list = encode_event_list(note_list)\n",
    "\" \".join(str(n) for n in encoded_note_list)[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_note():\n",
    "    \"\"\"\n",
    "    [S, 22, H, H, H, 33, H, H, H, R] -> [00001, 01000, 00001, 00002]\n",
    "    \"\"\"\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2024-10-06\n",
    "\n",
    "note: (pitch, duration, offset)\n",
    "\n",
    "- duration, offset \n",
    "    - no need for hold and rest tokens\n",
    "    - must be > 0, can do exp(duration)\n",
    "- if offset is from start of previous note, it can handle chords\n",
    "- output will be 3D\n",
    "\n",
    "data format\n",
    "\n",
    "- midi file -> midi python object -> representation -> model\n",
    "    - save representation to disk\n",
    "- do the data need to be further embedded inside the model evaluation?\n",
    "    - only if the model learns another intermediate representation?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_midi_to_event_sequence(\n",
    "    file: Path | str, target_key=m21.pitch.Pitch(\"C\")\n",
    ") -> list[tuple[int, float, float]]:\n",
    "    \"\"\"Read midi file to an event sequence in C\n",
    "\n",
    "    An event is of the form (pitch, duration, offset). The offset is the time interval since the last note ended.\n",
    "    Durations and offsets are in fractions of a quarter note.\n",
    "\n",
    "    Args:\n",
    "        file: Path to midi file\n",
    "        target_key: Key to transpose to. Defaults to C major / A minor.\n",
    "\n",
    "    Returns:\n",
    "        list of events\n",
    "    \"\"\"\n",
    "    song = m21.converter.parse(file)\n",
    "    if target_key is not None:\n",
    "        song = transpose_song(song, target_key=target_key)\n",
    "    instruments = m21.instrument.partitionByInstrument(song).parts\n",
    "    instrument = instruments[0]  # Use first instrument.\n",
    "    notes = []\n",
    "    offset = 0\n",
    "    for event in instrument.recurse():\n",
    "        # Note: To have duration in seconds, we would need to track tempo changes.\n",
    "        duration = event.duration.quarterLength\n",
    "        if isinstance(event, m21.note.Note):\n",
    "            pitch = event.pitch.midi\n",
    "        elif isinstance(event, m21.chord.Chord):\n",
    "            # note = tuple(n.pitch.midi for n in event.notes) # Save all notes as tuple.\n",
    "            pitch = event.notes[0].pitch.midi  # Save first note in chord.\n",
    "        elif isinstance(event, m21.note.Rest):\n",
    "            offset += duration\n",
    "            continue\n",
    "        else:\n",
    "            continue\n",
    "        notes.append((pitch, duration, offset))\n",
    "        offset = 0\n",
    "    return notes\n",
    "\n",
    "\n",
    "def transpose_song(song: m21.stream, target_key=m21.pitch.Pitch(\"C\")) -> m21.stream:\n",
    "    \"\"\"Transpose a music21 stream to a target key\n",
    "\n",
    "    Args:\n",
    "        song: music21 stream\n",
    "        target_key: Target key. Defaults to C major / A minor.\n",
    "\n",
    "    Returns:\n",
    "        transposed song (music21 stream)\n",
    "    \"\"\"\n",
    "    key = song.analyze(\"key\")\n",
    "    if key.mode == \"major\":\n",
    "        return song.transpose(m21.interval.Interval(key.tonic, target_key))\n",
    "    elif key.mode == \"minor\":\n",
    "        return song.transpose(\n",
    "            m21.interval.Interval(key.tonic, target_key.transpose(-3))\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(76, Fraction(1, 3), 4.0),\n",
       " (48, 0.75, 0),\n",
       " (67, Fraction(1, 3), 0),\n",
       " (60, 0.25, Fraction(1, 12)),\n",
       " (72, 0.25, 0.5),\n",
       " (50, 0.75, 0),\n",
       " (77, 0.25, 0),\n",
       " (77, 0.25, 0.25),\n",
       " (60, Fraction(1, 3), 0),\n",
       " (72, 0.25, 1.8333333333333333),\n",
       " (52, 1.0, 0),\n",
       " (72, 0.25, Fraction(1, 6)),\n",
       " (72, 0.25, 0.25),\n",
       " (79, Fraction(1, 3), 0),\n",
       " (81, Fraction(1, 3), 3.3333333333333335),\n",
       " (53, 1.0, 0),\n",
       " (81, Fraction(1, 3), 0),\n",
       " (81, 0.25, Fraction(1, 12)),\n",
       " (79, 0.25, 0.5),\n",
       " (52, 0.75, 0)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_sequence = read_midi_to_event_sequence(file)\n",
    "event_sequence[:20]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
